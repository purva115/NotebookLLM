

# NotebookLM Clone ğŸ““

> An AI-powered research assistant inspired by Google NotebookLM.  
> Upload documents, chat with them using RAG, and generate study artifacts â€” all in isolated per-user notebooks.

---

## Features

| Feature | Details |
|---|---|
| ğŸ“„ **Source Ingestion** | PDF, PPTX, TXT, web URLs, YouTube transcripts |
| ğŸ’¬ **RAG Chat** | Grounded answers with inline source citations |
| ğŸ“ **Artifacts** | Auto-generate Reports, Quizzes, and Podcast audio |
| ğŸ”’ **User Isolation** | Every user's data lives in their own directory |
| ğŸ“š **Multi-Notebook** | Create, rename, and delete multiple notebooks per user |
| ğŸ’¾ **Persistent Storage** | Files, chat history, and artifacts persist across sessions |

---

## Tech Stack

| Layer | Technology | Why |
|---|---|---|
| UI | Gradio 4 | Native HF Spaces support, no JS/CSS needed |
| Auth | Hugging Face OAuth | No password database, seamless HF integration |
| LLM | Google Gemini 1.5 Pro | Long context window, free tier available |
| Embeddings | `text-embedding-004` | High quality, same API key as Gemini |
| Vector DB | ChromaDB (per-notebook) | File-based, no server needed, fully isolated |
| Metadata DB | SQLite + SQLAlchemy | Zero-infra, works on HF Spaces persistent disk |
| CI/CD | GitHub Actions | Auto-pushes to HF Space on every commit |

---

## Project Structure

```
NotebookLM/
â”œâ”€â”€ app.py                          # Gradio app entry point (HF Spaces)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example                    # Copy to .env and fill in your keys
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ core/                       # Config, security helpers
â”‚   â”œâ”€â”€ ui/                         # Gradio tab components (auth, notebooks, chat, sources)
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ ingestion/              # PDF/PPTX/URL parser â†’ chunker â†’ embedder
â”‚   â”‚   â”œâ”€â”€ retrieval/              # Vector search + context builder
â”‚   â”‚   â”œâ”€â”€ llm/                    # Gemini client, RAG chat, summaries, audio
â”‚   â”‚   â””â”€â”€ storage/
â”‚   â”‚       â””â”€â”€ notebook_store.py   # All filesystem path logic (single source of truth)
â”‚   â””â”€â”€ db/                         # SQLite models + CRUD (notebooks, sources, chunks)
â”‚
â”œâ”€â”€ data/                           # Gitignored â€” created automatically at runtime
â”‚   â””â”€â”€ users/
â”‚       â””â”€â”€ <username>/
â”‚           â””â”€â”€ notebooks/
â”‚               â”œâ”€â”€ index.json                  # List of all notebooks
â”‚               â””â”€â”€ <notebook-uuid>/
â”‚                   â”œâ”€â”€ files_raw/              # Uploaded source files (PDF, PPTX, TXT)
â”‚                   â”œâ”€â”€ files_extracted/        # Extracted plain text per source
â”‚                   â”œâ”€â”€ chroma/                 # ChromaDB vector store (per notebook)
â”‚                   â”œâ”€â”€ chat/
â”‚                   â”‚   â””â”€â”€ messages.jsonl      # Chat history (one JSON object per line)
â”‚                   â””â”€â”€ artifacts/
â”‚                       â”œâ”€â”€ reports/            # report_1.md, report_2.md, ...
â”‚                       â”œâ”€â”€ quizzes/            # quiz_1.md, quiz_2.md, ...
â”‚                       â””â”€â”€ podcasts/           # podcast_1.mp3, podcast_2.mp3, ...
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/                       # Fast tests (no API keys needed)
â”‚   â””â”€â”€ integration/
â””â”€â”€ docs/                           # Architecture docs and design brief
```

---

## Required Environment Variables

Copy `.env.example` to `.env` and fill in:

| Variable | Description | Required |
|---|---|---|
| `GOOGLE_API_KEY` | Google AI Studio key (Gemini + Embeddings) | âœ… Yes |
| `SECRET_KEY` | Random 32-character string for session signing | âœ… Yes |
| `SQLITE_PATH` | Override SQLite DB path (default: `data/notebooklm.db`) | Optional |
| `DATA_DIR` | Override data root directory (default: `./data`) | Optional |

---

## Running Locally

```bash
# 1. Clone the repo
git clone https://github.com/purvas115/NotebookLLM.git
cd NotebookLLM

# 2. Install dependencies
pip install -r requirements.txt

# 3. Configure environment
cp .env.example .env
# Edit .env â€” fill in GOOGLE_API_KEY and SECRET_KEY

# 4. Start the app
python app.py
# Visit http://localhost:7860
```

---

## Deploying to Hugging Face Spaces

1. Create a **Gradio** Space on [huggingface.co](https://huggingface.co/spaces).
2. Push this repo to the Space:
   ```bash
   git remote add space https://huggingface.co/spaces/<your-org>/<your-space>
   git push space main
   ```
3. In **Space Settings â†’ Secrets**, add `GOOGLE_API_KEY` and `SECRET_KEY`.
4. In **Space Settings â†’ Storage**, attach a **Persistent Storage** volume mounted at `/data`.

> **Note:** On the free HF tier, `/data` is ephemeral â€” data resets if the Space rebuilds or sleeps after 48 hours of inactivity. This is fine for development. For production persistence, use a paid storage volume ($5/month).

---

## CI/CD (GitHub Actions)

A GitHub Actions workflow automatically syncs this repo to the HF Space on every push to `main`.

Add `HF_TOKEN` (a Hugging Face token with **write** access to your Space) as a GitHub repository secret under **Settings â†’ Secrets and variables â†’ Actions**.

---

## Running Tests

```bash
# Unit tests only (no API key required)
python -m pytest tests/unit/ -v

# All tests
python -m pytest -v
```

---

## Milestone Plan

| Milestone | Scope |
|---|---|
| **MVP** | HF OAuth + Notebook CRUD + PDF ingestion + RAG chat |
| **M2** | URL / YouTube ingestion, per-source AI summaries, artifact generation |
| **M3** | Podcast audio (TTS), persistent chat history, artifact downloads |
| **M4** | Additional file types, multi-speaker podcast, CI/CD, performance hardening |
